# Analysis: Deep Learning for Plant Disease Detection

[![Paper](https://img.shields.io/badge/Paper-Read-green)](https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2016.01419/full)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-blue)](https://huggingface.co/datasets/mohanty/PlantVillage)

<img src="https://raw.githubusercontent.com/spMohanty/PlantVillage-Dataset/master/generated_for_paper/plantvillage.jpg" alt="PlantVillage Dataset Sample" width="600"/>

This directory contains the experimental code and configurations for the paper:  
[**"Using Deep Learning for Image-Based Plant Disease Detection"**](https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2016.01419/full)  
*Mohanty et al. (2016)*

---

## ðŸ“‚ Code Organization

The experiment configurations are structured hierarchically to cover **60 unique experiments**, exploring all combinations of standard architectures, dataset types, splits, and training modes.

### Hierarchy
`[Architecture] / [Dataset_Type]-[Split] / [Training_Approach]`

| Layer | Options | Details |
| :--- | :--- | :--- |
| **1. Architecture** | `alexnet`, `googLeNet` | Standard deep CNN architectures. |
| **2. Dataset Type** | `color`, `grayscale`, `segmented` | Image preprocessing variations. |
| **3. Split** | `80-20` to `20-80` | Train/Test split ratios. |
| **4. Approach** | `Train From Scratch`, `Finetuning` | Initialization strategy (Random vs ImageNet). |

---

## ðŸ› ï¸ Experiment Directory Structure

Each leaf directory (e.g., `alexnet/color-80-20/Train From Scratch/`) is a self-contained experiment environment:

| File / Folder | Function | Description |
| :--- | :--- | :--- |
| **`train.sh`** | **Training** | Script to initiate model training via Caffe. |
| **`test.sh`** | **Testing** | Iterates through saved snapshots to run inference. |
| **`results/`** | **Analysis** | Scripts to generate confusion matrices and graphs. |
| `*.prototxt` | **Config** | Neural network definitions (Solver, Train/Val, Deploy). |
| `caffe.log` | **Logs** | Raw training output log. |
| `hdf5_dumps/` | **Data** | (Generated) Raw predictions and labels for analysis. |

---

## âš ï¸ Prerequisites & Setup

> [!WARNING]
> **Legacy Codebase (Caffe Era)**: This project was built during the Caffe era (2015-2016) and uses **Python 2.7**. It is provided **"as is"** for reference and reproducibility purposes. Modernizing it to PyTorch/TensorFlow would require a complete rewrite.

To reproduce these experiments, ensure you have:
1.  **Caffe Framework**: Installed and in your system path.
2.  **LMDB Dataset**: The PlantVillage dataset converted to LMDB format.
3.  **GPU Compute**: Training on CPU is not recommended.

### Path Configuration

> [!IMPORTANT]
> **Action Required**: The provided scripts contain hardcoded paths (e.g., `/scratch/mohanty/...`) specific to the original computing cluster. You **must** find and replace these with your local paths before running.

**Files to Update:**
*   `solver.prototxt`: Update `net` (path to train_val) and `snapshot_prefix` (snapshot storage).
*   `train_val.prototxt`: Update `source` paths for TRAIN and TEST LMDBs.
*   `test.sh`: Update paths to the `caffe` binary and your snapshot directory.

---

## ðŸš€ Workflow

### 1. Training
Navigate to your chosen experiment directory and start the training job.
```bash
cd alexnet/color-80-20/Train\ From\ Scratch/
./train.sh
```

### 2. Testing
Once training is complete, run the test script to evaluate all model snapshots.
```bash
./test.sh
```
*This step generates `hdf5_dumps` used for analysis.*

### 3. Analysis
Generate performance graphs, classification reports, and confusion matrices.
```bash
cd results
./generate_results.sh
```
*Outputs will be saved in `results/classification_reports`, `results/confusion_matrices`, etc.*

---


## In-the-wild Evaluation

This repository includes the results of the "In-the-wild" evaluation described in the paper, where models were tested on images found on the internet to assess generalization.

-   [**`bing_results.csv`**](./bing_results.csv): Results from images collected via Bing Image Search.
-   [**`ipm_results.csv`**](./ipm_results.csv): Results from images collected from IPM (Integrated Pest Management) resources.

Both files follow the format: `URL, Actual Label, Predicted Label`.

## Acknowledgements

The segmented version of the dataset used in this paper was generated by [**Boris Conforty**](https://github.com/Boris-c).  
For details on the segmentation process, please refer to:
*   [**`PlantVillageSegmentation.pdf`**](./PlantVillageSegmentation.pdf) (included in this repository)

## ðŸ“„ Citation

```bibtex
@article{Mohanty_Hughes_SalathÃ©_2016,
    title   = {Using deep learning for image-based plant disease detection},
    volume  = {7},
    DOI     = {10.3389/fpls.2016.01419},
    journal = {Frontiers in Plant Science},
    author  = {Mohanty, Sharada P. and Hughes, David P. and SalathÃ©, Marcel},
    year    = {2016},
    month   = {Sep}
} 
```

## ðŸ‘¥ Authors

**Sharada Mohanty** <sharada.mohanty@epfl.ch>  
**Marcel SalathÃ©** <Marcel.Salathe@epfl.ch>  
*Digital Epidemiology Lab, EPFL*
